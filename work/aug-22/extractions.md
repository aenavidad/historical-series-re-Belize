# extractions

## abstract

this file logs activities, decisions, reasoning and the like related to extraction, cleaning, and processing of files tagged in [[tagged]] for output of `v-1.5`[^file created 21 aug 2022 20.16 in Boston MA.]

## sources

re ~~47~~57 files topically grouped as **sources and authorities** in [[tagged]]

start

1. start on 21 aug 2022 20.17,
2. order files chronologically as per [[pre-git-hist/events.tsv]] to better navigate files and to weed out duplicate datavalues,
    - output from most to least recent is `grey/series-v-1.5-*.tsv`, `yell/sources *.tsv`, `harv/found bib 1.2-*.tsv`, `harv/found scrap 1.2-*.tsv`, `harv/found data 1.2-*.tsv`, `harv/1638 sources 1.5-Sources *.tsv`, ~~`detour at 20.27`~~, ~~`detour at 20.38`~~, `purp/disc amb 1.1 *.tsv`, `tran/hist sources 1.4 *.tsv`, `tran/hist sources v1.3 *.tsv`, `blue/hist sources v1.1 *.tsv`, `harv/Sources-*.tsv`, `harv/Sources 2-*.tsv`.
3. `detour at 20.27` taken to add 5 `disc amb 1.1 *.tsv` files to `pre-git-hist/files/purp/` and to [[pre-git-hist/files.tsv]],
4. `detour at 20.38` taken to add `purp/disc amb 1.1 *.tsv` and `tran/hist sources 1.4 *.tsv` and `tran/hist sources v1.3 *.tsv` to `tagged.md` thereby bringing files grouped as *sources and authorities* from 47 total to 57 total,
5. determine duplicate datavalues within `grey/series-v-1.5-*.tsv`, and further weed out sparse or useless files,
    - output alphabetically ordered is,
        - `authorities-context-Table 1` deemed sparse as has only tabular metadata,
        - `authorities-data-0-Table 1` deemed sparse as has only id values and a few isni.org, wikidata.org, and ror.org URIs,
        - `authorities-data-1-Table 1` deemed duplicate of `authorities-data-4-Table 1`,
        - `authorities-data-2-Table 1` deemed duplicate of `authorities-data-4-Table 1`,
        - `authorities-data-3-Table 1` deemed duplicate of `authorities-data-4-Table 1`,
        - `authorities-data-4-Table 1` deemed original though duplicates values from one or more `yell/sources *.tsv` files,
        - `authorities-data-5-Table 1` deemed sparse as has only one schema.org URI,
        - `authorities-meta-Table 1` deemed sparse as has only tabular metadata,
        - `authorities-type-Table 1` deemed sparse as has only tabular metadata,
        - `graphs-data-0-Table 1` deemed sparse as has only one id value,
        - `graphs-meta-Table 1` deemed sparse as has only tabular metadata,
6. of 11 `grey/series-v-1.5-*.tsv` files, decided to proceed only with those not deemed sparse nor duplicates ie only with 1 `grey/series-v-1.5-*.tsv` file ie `grey/series-v-1.5-authorities-data-4-Table 1.tsv`,
7. repeat step 5 for `yell/sources *.tsv`,
    - output alphabetically ordered is,
        - `collections 1.1 Code-Table 1` deemed original though duplicates (encoded) values from vars `red/`, `purp/`, `blue/`, and `wiki/` files,
        - `collections 1.1 Collections-Table 1` deemed duplicate of `collections 1.2 Collections-Table 1`,
        - `collections 1.1 Introduction-Table 1` deemed sparse as has only tabular metadata and log details,
        - `collections 1.1 Not Collections-Table 1` deemed original,
        - `collections 1.2 Collections-Table 1` deemed original,
        - `collections 1.2 Sheet 1-Table 1` deemed sparse as has only tabular metadata and log details,
        - `not collections 1.1 Intro-Table 1` deemed sparse as has only description of "Mana 3",
        - `not collections 1.1 Mana 3-Table 1` deemed sparse as has only 3 URIs for 3 Harvard Dataverse repositories,
8. of 8 `yell/sources *.tsv` files, decided as in step 6 ie only with 3 `yell/sources *.tsv` files ie `yell/sources collections 1.1 Code-Table 1.tsv` and `yell/sources collections 1.1 Not Collections-Table 1.tsv` and `yell/sources collections 1.2 Collections-Table 1.tsv`,
9. repeat step 5 for `harv/found bib 1.2-*.tsv`,
    - output alphabetically ordered is,
        - `Intro-Table 1` deemed sparse as has only tabular log details,
        - `Minkel asdf-Table 1` deemed original,
        - `Navidad asdf-Table 1` deemed duplicate of `yell/sources collections 1.1 Code-Table 1.tsv`,
        - `O'Ryan asdf-Table 1` deemed original,
        - `Reyes asdf-Table 1` deemed original,
10. of 5 `harv/found bib 1.2-*.tsv` files, decided as in step 6 ie only with 3 `harv/found bib 1.2-*.tsv` files ie `harv/found bib 1.2-Minkel asdf-Table 1.tsv` and `harv/found bib 1.2-O'Ryan asdf-Table 1.tsv` and `harv/found bib 1.2-Reyes asdf-Table 1.tsv`,
11. repeat step 5 for `harv/found scrap 1.2-*.tsv`,
    - output alphabetically ordered is,
        - `Blue recs 169-Table 1` deemed duplicate of `yell/sources collections 1.1 Code-Table 1.tsv`,
        - `Purple recs 460-Table 1` deemed duplicate of `yell/sources collections 1.1 Code-Table 1.tsv`,
        - `Red recs 1107-Table 1` deemed duplicate of `yell/sources collections 1.1 Code-Table 1.tsv`,
        - `Sum recs 2613-Table 1` deemed duplicate of `yell/sources collections 1.1 Code-Table 1.tsv`,
        - `Sum recs adfasd-Table 1` deemed duplicate of `yell/sources collections 1.1 Code-Table 1.tsv`,
        - `Sum recs w formulas-Table 1` deemed duplicate of `yell/sources collections 1.1 Code-Table 1.tsv`,
        - `Wiki recs ???-Table 1` deemed duplicate of `yell/sources collections 1.1 Code-Table 1.tsv`,
        - `Wiki recs 877-Table 1` deemed duplicate of `yell/sources collections 1.1 Code-Table 1.tsv`,
        - `Wiki recs asdf-1-Table 1` deemed duplicate of `yell/sources collections 1.1 Code-Table 1.tsv`,
        - `Wiki recs asdf-Table 1` deemed duplicate of `yell/sources collections 1.1 Code-Table 1.tsv`,
        - `Wiki recs jhkl-1-Table 1` deemed duplicate of `yell/sources collections 1.1 Code-Table 1.tsv`,
12. of 11 `harv/found scrap 1.2-*.tsv` files, decided as in step 6 ie only with 0 ie none `harv/found scrap 1.2-*.tsv` files,
13. repeat step 5 for `harv/found data 1.2-*.tsv`,
    - output alphabetically ordered is,
        - `AN - sum 2613-Table 1` deemed duplicate of `yell/sources collections 1.1 Code-Table 1.tsv`,
        - `Harvest 1-Table 1` deemed original,
        - `Harvest scrap-Table 1` deemed duplicate of `Harvest 1-Table 1`,
        - `OCLC - sum ???-Table 1` deemed sparse as has only oclc.org-generated values,
        - `Partitions 6-Table 1` deemed original,
14. of 5 `harv/found data 1.2-*.tsv` files, decided as in step 6 ie only with 2 `harv/found data 1.2-*.tsv` files ie `harv/found data 1.2-Harvest 1-Table 1.tsv` and `harv/found data 1.2-Partitions 6-Table 1.tsv`
15. repeat step 5 for `harv/1638 sources 1.5-Sources *.tsv`,
    - output alphabetically ordered is,
        - `Introduction-Table 1` deemed sparse as has only tabular metadata and log details,
        - `Sources ss?-?-Table 1` deemed original,
16. of 2 `harv/1638 sources 1.5-Sources *.tsv` files, decided as in step 6 ie only with 1 `harv/1638 sources 1.5-Sources *.tsv` file ie `harv/1638 sources 1.5-Sources Sources ss?-?-Table 1.tsv`
17. repeat step 5 for `purp/disc amb 1.1 *.tsv`,
    - output alphabetically ordered is,
        - `Guides-Table 1` deemed sparse as has only Oxford Bibliographies article URIs,
        - `Intro-Table 1` deemed sparse as has only tabular log details,
        - `Oxford-Table 1` deemed original,
        - `SH-Table 1` deemed sparse as has only LCSH URIs,
        - `Works-Table 1` deemed original,
18. of 5 `purp/disc amb 1.1 *.tsv` files, decided as in step 6 ie only with 2 `purp/disc amb 1.1 *.tsv` files ie `purp/disc amb 1.1 Oxford-Table 1.tsv` and `purp/disc amb 1.1 Works-Table 1.tsv`,
19. repeat step 5 for `tran/hist sources 1.4 *.tsv`,
    - output alphabetically ordered is,
        - `so Items-so Items Manu* repositories.` deemed original,
        - `xxx-so Items Manu* repositories.` deemed sparse as has no values,
20. of 2 `tran/hist sources 1.4 *.tsv` files, decided as in step 6 ie only with 1 `tran/hist sources 1.4 *.tsv` file ie `tran/hist sources 1.4 so Items-so Items Manu* repositories..tsv`,
21. repeat step 5 for `tran/hist sources v1.3 *.tsv`,
    - output alphabetically ordered is,
        - `se Collectors-1-Table 1` deemed sparse as has only few values,
        - `se Collectors-Table 1` deemed sparse as has only tabular log details,
        - `so Collections-Table 1` deemed sparse as has no values,
22. of 3 `tran/hist sources v1.3 *.tsv` files, decided as in step 6 ie only with 0 ie none `tran/hist sources v1.3 *.tsv` files,
23. repeat step 5 for `blue/hist sources v1.1 *.tsv`
    - output alphabetically ordered is,
        - `Collections-Table 1` deemed original,
        - `Repositories-Table 1` deemed original,
        - `Works-Table 1` deemed sparse as has no values,
24. of 3 `blue/hist sources v1.1 *.tsv` files, decided as in step 6 ie only with 2 `blue/hist sources v1.1 *.tsv` ie `blue/hist sources v1.1 Collections-Table 1.tsv` and `blue/hist sources v1.1 Repositories-Table 1.tsv`,
25. repeat step 5 for `harv/Sources-*.tsv`
    - output alphabetically ordered is,
        - `harv/Sources-*.tsv` deemed duplicate of `yell/sources collections 1.1 Code-Table 1.tsv`,
26. of 1 `harv/Sources-*.tsv` file, decided as in step 6 ie only with 0 ie none `harv/Sources-*.tsv` file,
27. repeat step 5 for `harv/Sources 2-*.tsv`
    - output alphabetically ordered is,
        - `harv/Sources 2-*.tsv` deemed duplicate of `yell/sources collections 1.1 Code-Table 1.tsv`,
28. of 1 `harv/Sources 2-*.tsv` file, decided as in step 6 ie only with 0 ie none `harv/Sources 2-*.tsv` file,
29. order files accepted in steps 5-28 chronologically for same reason as in step 2,
    - output begins,
    - `grey/series-v-1.5-authorities-data-4-Table 1.tsv`,
    - `yell/sources collections 1.1 Code-Table 1.tsv`,
    - `yell/sources collections 1.1 Not Collections-Table 1.tsv`,
    - `yell/sources collections 1.2 Collections-Table 1.tsv`,
    - `harv/found bib 1.2-Minkel asdf-Table 1.tsv`,
    - `harv/found bib 1.2-O'Ryan asdf-Table 1.tsv`,
    - `harv/found bib 1.2-Reyes asdf-Table 1.tsv`,
    - `harv/found data 1.2-Harvest 1-Table 1.tsv`,
    - `harv/found data 1.2-Partitions 6-Table 1.tsv`,
    - `harv/1638 sources 1.5-Sources Sources ss?-?-Table 1.tsv`,
    - `purp/disc amb 1.1 Oxford-Table 1.tsv`,
    - `purp/disc amb 1.1 Works-Table 1.tsv`,
    - `tran/hist sources 1.4 so Items-so Items Manu* repositories..tsv`,
    - `blue/hist sources v1.1 Collections-Table 1.tsv`,
    - `blue/hist sources v1.1 Repositories-Table 1.tsv`,
    - output ends,
30. call files in step 29 *step 29 accepted files* or *accepted files*,
31. decide to use [the W3C csv-dialect](https://www.w3.org/2013/csvw/wiki/Main_Page) for csv files and json in [no particular dialect](https://en.wikipedia.org/wiki/JSON) for json files expected to be written soon,
32. `detour at 22.16` taken to review documentation cited in step 31,
    - output begins,
    - tag json standards as [RFC 8259](https://tools.ietf.org/html/rfc8259) and its associated errata, and [ECMA 404](https://www.ecma-international.org/publications-and-standards/standards/ecma-404/),
    - tag W3C csv-dialect standards as 7 working group documents ie [Model](http://www.w3.org/TR/2015/REC-tabular-data-model-20151217/), [Metadata Vocab](http://www.w3.org/TR/2015/REC-tabular-metadata-20151217/), [Generating JSON](http://www.w3.org/TR/2015/REC-csv2json-20151217/), [Generating RDF](http://www.w3.org/TR/2015/REC-csv2rdf-20151217/), [Use Cases and Requirements](http://www.w3.org/TR/2016/NOTE-csvw-ucr-20160225/), [Embedding in HTML](http://www.w3.org/TR/2016/NOTE-csvw-html-20160225/), and [Primer](http://www.w3.org/TR/2016/NOTE-tabular-data-primer-20160225/),
    - skimmed RFC 2859 at 22.37 to 22.42 with comments `null`,
    - skimmed Primer at 22.43 to 23.38 with comments as follows,
        - comments begin,
        - per sec 1.2 should name metadata `*.csv-metadata.json` for datafile `*.csv`,
        - per sec 2.1 may use Dublin Core, schema.org, DCAT, etc in metadata where recognised-vocab-prefixes are those in [RFDa 1.1 Initial Context](https://www.w3.org/2011/rdfa-context/rdfa-1.1),
        - per sec 2.4 may not be desirable to annotate individual cells in metadata as this isn't standardised by the dialect but is nonetheless possible,
        - per sec 3.1 built-in datatypes for file validation are those in [XSD 1.1 Part 2 Datatypes](http://www.w3.org/TR/xmlschema11-2/),
        - per sec 3.2 may define new datatypes for file validation as restrictions of built-in datatypes,
        - per sec 3.3-3.10 may restrict or define string, numerical, date-time, boolean values for file validation,
        - per sec 3.11 may allow variables to accept more than one datatype for file validation,
        - per sec 3.12 may allow variables to accept lists of values for file validation,
        - per sec 3.13 may require value for each edge ie row for file validation,
        - per sec 4.1 may transform `*.csv` datafiles to JSON or RDF given the corresponding `*.csv-metadata.json` metadata,
        - per sec 4.10 may add virtual columns in metadata to help transformation of csv to JSON or RDF,
        - per sec 4.12 may transform csv to JSON-LD by transforming to RDF and then emitting to JSON-LD (though "emit" is not defined in the document so may need to see Generating RDF),
        - per sec 4.14 may transform csv to [RDF Data Cube](http://www.w3.org/TR/vocab-data-cube/) eg for statistical values eg [cf this fully worked-out eg using meteorological datavalues](https://github.com/w3c/csvw/blob/gh-pages/examples/rdf-data-cube-example.md),
        - per sec 4.15 may transform csv to formats other than RDF or JSON (though does not seem easy),
        - per sec 5.4 may specify natural-language of string datavalues,
        - per sec 6.1 there is no built-in support to specify units of measure though may add virtual columns in metadata ensure inclusion of these in transformation output,
        - per sec 6.2 there is no single best practice for geospatial datavalues in csv though points may be easily specified while other geometries (eg in GeoJSON) may be defined as datatypes,
        - per sec 6.4 may define row titles, 
        - comments end,
    - skimmed Model on 22 aug 2022 0.08 to 0.31 with comments as follows,
        - begin comments,
        - sec 4.1-4.6 list information (re sets of tables, individual tables, columns, rows, cells, and datatypes) required in metadata for validation or transformation of csv files,
        - sec 6.4 list formats for built-in datatypes,
        - sec 7.1-7.4 lists syntax best practice for the csv dialect,
        - end comments, 
    - skimmed Metadata Vocab on 0.31 to 0.40 with comments,
        - begin comments,
        - sec 5 specifies format for metadata,
        - end comments,
    - skimmed Use Cases and Requirements with comments,
        - begin comments,
        - sec 3.1 lists requirements met by the csv-dialect ie its benefits ie features,
        - end comments,
    - output ends,
33. `detour at 22.16` ended at 22 aug 2022 1.09,
34. pause on 22 aug 2022 1.10,
35. continue on 22 aug 2022 6.36,
36. decide data extracted from *step 29 accepted files* to be routed to the following files,
    - start output,
    - `authorities.csv` for entities holding or managing digital or non-digital collections of print or non-print items,
    - `authorities.csv-metadata.json`,
    - `works.csv` for named collections of digital or non-digital or print or non-print items or of said items themselves,
    - `works.csv-metadata.json`,
    - `vertices.csv` for vertices,
    - `vertices.csv-metadata.json`,
    - `edges.csv` for edges,
    - `edges.csv-metadata.json`,
    - `d-function.csv` for the d function,
    - `d-function.csv-metadata.json`,
    - end output,
37. decide to locate step 36 files in `work/aug-22/` directory,
38. step 36 files written to directory named in step 38 using TextEdit Version 1.16 (365.2) on 6.57,
39. `detour at 7.10` taken to find regular expression ie regex standards for csvw and json,
    - start output,
    - may want regex to conform to [I-Regexp](https://www.ietf.org/id/draft-ietf-jsonpath-iregexp-01.html) as this meant to be interoperable,
    - end output,
40. decide to reserve the following ids for vertices in `vertices.csv`, edges in `edges.csv`, d-function mappings in `d-function.csv`,
    - start output,
    - set `num = [0-9][0-9][0-9][0-9]` ie `0000-9999`,
    - `v[a-z][a-z]num` for vertices,
    - `e[a-z][a-z]num` for edges,
    - `d[a-z][a-z]num` for d-function mappings,
    - reserve `va[a-z]num` for vertices wholly contained within the graph eg tables, records, files, and the like,
    - reserve `vaanum` for files,
    - end output,
41. start writing [[vertices.csv]] at 7.57,
    - start ouput,
    - further reserve `vaanum` for files and add to step 40,
    - end output,
42. start writing [[vertices.csv-metadata.json]] at 8.41,
    - start ouput,
    - decide to specify all 10 properties for tables as listed in [Metadata fig 1](https://www.w3.org/TR/2015/REC-tabular-metadata-20151217/#metadata-format) except those omitted in step 42,
    - decide to omit the `dialect` property for tables ie to use default value for said property as given in [Metadata sec 5.9](https://www.w3.org/TR/2015/REC-tabular-metadata-20151217/#dialect-descriptions),
    - decide to use `http://example.org/` as placeholder value for the `@base` subproperty of `@context` property for tables as per [Metadata sec 5.2](https://www.w3.org/TR/2015/REC-tabular-metadata-20151217/#top-level-properties),
    - decide to omit the `suppressOutput` property for tables ie to use devault value for said property as per Metadata sec 5.4.2,
    - `detour at 10.01` taken,
    - `detour at 10.23` taken,
    - decide to omit the `notes` property for tables,
    - decide to omit the `transformations` property for tables,
    - after 4 omissions the file specifies 6 of the 10 properties for tables as listed in Metadata fig 1,
    - during the specification of the 6 properties for tables as listed in Metadata fig 1 we gave the value of the `@context` property for tables as an array of a string and an object with the latter containing two objects (one to specify `@language` and another for `@base`) as per [Metadata sec 5.2](https://www.w3.org/TR/2015/REC-tabular-metadata-20151217/#top-level-properties),
    - decided to specify all 6 subproperties for `tableSchema` as per Metadata fig 1 except those omitted in step 42,
    - decide to omit the `@id` subproperty of `tableSchema` property,
    - decide to omit the `foreignKeys` subproperty of `tableSchema` property,
    - decide to omit the `rowTitles` subproperty of `tableSchema` property,
    - after 3 omissions the file specifies 3 of hte 6 subproperties of the `tableSchema` property for tables as listed in Metadata fig 1,
    - decided to specify all 7 subsubproperties of the `columns` subproperty of the `tableSchema` property for tables except those omitted in step 42,
    - decide to omit the `@id` subsubproperty of `columns` subproperty of `tableSchema`,
    - decide to omit the `titles` subsubproperty of `columns` subproperty of `tableSchema`,
    - decide to omit the `suppressOutput` subsubproperty of `columns` subproperty of `tableSchema`,
    - decide to omit all 11 subsubproperties called *Inherited Properties* of `columns` subproperty of the `tableSchema` property for tables except those inserted in step 42,
    - inserted `required` subsubproperty ie *Inherited Properties* of `columns` subproperty of `tableSchema`,
    - insterted `datatype` subsubproperty ie *Inherited Properties* of `columns` subproperty of `tableSchema`,
    - inserted `default` subsubproperty ie *Inherited Properties* of `columns` subproperty of `tableSchema`,
    - decided to assign all 11 *Inherited Properties* as identified in Metadata fig 1 or Metadata sec 5.7 to one of table-group-description, table-description, schema-description, or column-description as these *-description terms are defined in Metadata,
    - `detour at 12.10` taken,
    - `detour at 12.17` taken,
    - end output,
43. `detour at 10.01` taken to amend details given in step 31,
    - begin output,
    - read *decide to use [the W3C csv-dialect](https://www.w3.org/2013/csvw/wiki/Main_Page) for csv files* as identifying `csvw` as the dialect used for csv files as per [Metadata sec 5.9](https://www.w3.org/TR/2015/REC-tabular-metadata-20151217/#dialect-descriptions) though this dialect has not been checked for compliance with Model sec 7 nor Model sec 8,
    - read *json in [no particular dialect](https://en.wikipedia.org/wiki/JSON) for json files* as identifying `csvm+json` as the dialect used for json files as per [Metadata sec C](https://www.w3.org/TR/tabular-metadata/#iana-considerations) ie [IANA Registry](https://www.iana.org/assignments/media-types/application/csvm+json),
    - end output,
44. `detour at 10.23` taken to check compliance of dialect given in Metadata sec 5.9 with Model sec 7 and Model sec 8 as noted in setp 43,
    - begin output,
    - Model sec 7.0 (ie prior to sec 7.1) permits CRLF and LF line endings only though [RFC 4180](https://tools.ietf.org/html/rfc4180) permits CRLF only,
    - Model sec 7.1 requires `text/csv` file content type,
    - Model sec 7.2 recommends UTF-8 encoding in [Unicode Normal Form C](http://www.unicode.org/reports/tr15),
    - Model sec 7.3 recommends CLRF (U+000D U+000A) line endings,
    - Model sec 7.4.0 (ie prior to sec 7.4.1) recommends same number of csv per line,
    - Model sec 7.4.1 recommends first line be set as header line,
    - Model sec 7.5 permits no comments,
    - note Metadata sec 5.9 disagrees with Model sec 8 as former sets `commentPrefix` to `#` while latter sets it to `null`,
    - decide to prefer Metadata sec 5.9 as the csv dialect though comments likely not to be escaped with any character eg `#` within csv files,
    - end output,
45. continue output of step 42 at 10.50,
46. `detour at 12.10` taken to write `graph.csv-metadata.json` file,
    - begin output,
    - add `graph.csv-metadata.json` to files listed in step 36,
    - write `graph.csv-metadata.json`,
    - add vertex representing this file to `vertices.csv`,
    - end output,
47. `detour at 12.17` taken to add edges to `edges.csv`
    - begin ouput,
    - end output,
48. paused steps 45-47 on 12.28,
49. continued on 12.46,
50. `detour at 12.46` taken to write `detour-at-12-46.md` file,
51. continued on 23 aug 2022 1.36,
52. `detour at 1.54` taken to write `detour-at-1-54.md` file,
53. `detour at 2.20` taken to convert all filenames of files within `work/aug-22` to [iA Writer WikiLinks](https://ia.net/writer/support/general/wikilinks),[^with minor detour taken just prior to 2.56 to make commits to the `historical-series-re-Belize` repo, to merge `aug-tagging` branch to main branch, to clone both repos in `github.com/aenavidad/` to iCloud directory `/Users/angelnavidad/Library/Mobile Documents/com~apple~CloudDocs/GitHub`, and to add this directory to iA Writer Locations so as to enable WikiLinks within all these documents (though only documents in `work/aug-22` are being WikiLinked during `detour at 2.20`)]

end