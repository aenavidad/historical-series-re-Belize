no	standard	link	no	adoption	note	extract
1	AN `process-0.md`	https://github.com/aenavidad/historical-series-re-Belize/tree/main/work/aug-22	no 1	yes	`work` must be replicable	`null`
2	AN `process-0.md`	https://github.com/aenavidad/historical-series-re-Belize/tree/main/work/aug-22	no 2	yes	`v-1.5` must be human-readable	`null`
3	AN `process-0.md`	https://github.com/aenavidad/historical-series-re-Belize/tree/main/work/aug-22	no 3	yes	`v-1.5` must be machine-readable	`null`
4	AN `process-0.md`	https://github.com/aenavidad/historical-series-re-Belize/tree/main/work/aug-22	no 1.1	yes	`work-files` must cite sources	`null`
5	AN `process-0.md`	https://github.com/aenavidad/historical-series-re-Belize/tree/main/work/aug-22	no 1.2	yes	`work-files` must be archived	`null`
6	AN `process-0.md`	https://github.com/aenavidad/historical-series-re-Belize/tree/main/work/aug-22	no 1.3	yes	`work` must be logged	`null`
7	AN `process-0.md`	https://github.com/aenavidad/historical-series-re-Belize/tree/main/work/aug-22	no 1.4	yes	`work` must be registered	`null`
8	AN `process-0.md`	https://github.com/aenavidad/historical-series-re-Belize/tree/main/work/aug-22	no 1.5	yes	`pre-git-files` and `work-files` must be licensed	`null`
9	AN `process-0.md`	https://github.com/aenavidad/historical-series-re-Belize/tree/main/work/aug-22	no 1.6	yes	`work-files` must be citeable	`null`
10	AN `process-0.md`	https://github.com/aenavidad/historical-series-re-Belize/tree/main/work/aug-22	no 1.7	yes	`v-1.5` must inc metadata	`null`
11	COS TOP Guidelines	https://www.cos.io/initiatives/top-guidelines	no 1 lvl iii	yes	`work-files` must *appropriately* cite sources	Article is not published until providing appropriate citation for data and materials
12	COS TOP Guidelines	https://www.cos.io/initiatives/top-guidelines	no 2 lvl ii	yes	`work-files` must be archived *in trusted repository*	Data must be posted to a trusted repository. Exceptions must be identified at article submission
13	COS TOP Guidelines	https://www.cos.io/initiatives/top-guidelines	no 3 lvl ii	yes	as no 2 lvl ii	Code must be posted to a trusted repository. Exceptions must be identified at article submission
14	COS TOP Guidelines	https://www.cos.io/initiatives/top-guidelines	no 4 lvl ii	yes	as no 2 lvl ii	Materials must be posted to a trusted repository. Exceptions must be identified at article submission
15	COS TOP Guidelines	https://www.cos.io/initiatives/top-guidelines	no 5 lvl iii	yes	`pre-print` must inc design and log details of `work`	Journal requires and enforces adherence to design transparency standards for review and publication
16	COS TOP Guidelines	https://www.cos.io/initiatives/top-guidelines	no 6 lvl i	no	may not be possible as study started oct 2020	"Article states whether preregistration of study exists, and, if so, where to access it"
17	COS TOP Guidelines	https://www.cos.io/initiatives/top-guidelines	no 7 lvl i	yes	`work` must be registered	"Article states whether preregistration of study exists, and, if so, where to access it"
18	COS TOP Guidelines	https://www.cos.io/initiatives/top-guidelines	no 8 lvl i	no	may not be possible as requires third-party	Journal encourages submission of replication studies
19	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	principle 2	no	re URIs but language is too vague	global naming leads to global network effects
20	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	practice 2.1	yes	`work-files` must identify resources via URIs	agents should provide URIs as identifiers for resources
21	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	constraint 2.2	yes	as practice 2.1 adding *distinct resources via distinct URIs*	assign distinct URIs to distinct resources
22	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	practice 2.3.1	yes	as practice 2.1 adding *in one-to-one mapping*	a URI owner SHOULD NOT associate arbitrarily different URIs with the same resource
23	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	practice 2.3.1	no	may not be possible (eg given journal-imposed citation styles)	"an agent that receives a URI SHOULD refer to the associated resource using the same URI, character-by-character"
24	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	practice 2.4	yes	as practice 2.1 adding *URI conforming to existing scheme eg https*	a specification SHOULD reuse an existing URI scheme (rather than create a new one) when it provides the desired properties of identifiers and their relation to resources
25	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	practice 2.5	no	not relevant	agents making use of URIs SHOULD NOT attempt to infer properties of the referenced resource
26	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	practice 3.2	no	not relevant	new protocols created for the Web SHOULD transmit representations as octet streams typed by Internet media types
27	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	contraint 3.3	no	not relevant	agents MUST NOT ignore message metadata without the consent of the user
28	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	practice 3.3	no	not relevant	server managers SHOULD allow representation creators to control the metadata associated with their representations
29	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	principle 3.4	no	not relevant	agents do not incur obligations by retrieving a representation
30	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	practice 3.5	no	not relevant	a URI owner SHOULD provide representations of the resource it identifies
31	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	principle 3.5	no	not relevant	an application developer or specification author SHOULD NOT require networked retrieval of representations each time they are referenced
32	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	practice 3.5.1	no	may not be possible (eg copyrighted material)	a URI owner SHOULD provide representations of the identified resource consistently and predictably
33	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	practice 4.2.1	no	not relevant	a data format specification SHOULD provide for version information
34	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	practice 4.5.7	no	xml-specific	"in general, a representation provider SHOULD NOT assign Internet media types beginning with ""text/"" to XML representations"
35	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	practice 4.5.7	no	xml-specific	"in general, a representation provider SHOULD NOT specify the character encoding for XML data in protocol headers since the data is self-describing"
36	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	practice 4.5.5	no	xml-specific	a specification in which QNames serve as resource identifiers MUST provide a mapping to URIs
37	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	constraint 4.5.5	no	xml-specific	do not allow both QNames and URIs in attribute values or element content where they are indistinguishable
38	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	practice 4.5.4	no	xml-specific	the owner of an XML namespace name SHOULD make available material intended for people to read and material optimized for software agents in order to meet the needs of those who will use the namespace vocabulary
39	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	practice 4.5.3	no	xml-specific	a specification that establishes an XML vocabulary SHOULD place all element names and global attribute names in a namespace
40	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	practice 4.4	no	not relevant	"a specification SHOULD provide ways to identify links to other resources, including to secondary resources (via fragment identifiers)"
41	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	practice 4.4	no	not relevant	"a specification SHOULD allow Web-wide linking, not just internal document linking"
42	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	practice 4.4	no	not relevant	a specification SHOULD allow content authors to use URIs without constraining them to a limited set of URI schemes
43	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	practice 4.4	no	not relevant	a data format SHOULD incorporate hypertext links if hypertext is the expected user interface paradigm
44	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	practice 4.3	no	not relevant	a specification SHOULD allow authors to separate content from both presentation and interaction concerns
45	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	practice 4.2.3	no	not relevant	a specification SHOULD provide mechanisms that allow any party to create extensions
46	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	practice 4.2.3	no	not relevant	extensibility MUST NOT interfere with conformance to the original specification
47	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	practice 4.2.3	no	not relevant	a specification SHOULD specify agent behavior in the face of unrecognized extensions
48	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	practice 4.2.2	no	xml-specific	an XML format specification SHOULD include information about change policies for XML namespaces
49	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	principle 5.1	no	language too vague	orthogonal abstractions benefit from orthogonal specifications
50	W3C Architecture of the WWW Vol I	http://www.w3.org/TR/webarch/	principle 5.3	no	language too vague or not relevant	agents that recover from error by making a choice without the user's consent are not acting on the user's behalf
51	Springer Nature Data Policies	https://www.springernature.com/gp/authors/research-data-policy/	data type 3	yes	`pre-git-files` and `work-files` must be licensed and must be archived and must be citeable 	data sharing encouraged and statements of data availability required
52	Springer Nature Data Policies	https://www.springernature.com/gp/authors/research-data-policy/	data type 4	no	may not be possible as requires third-party	"data sharing, evidence of data sharing and peer review of data required"
53	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 1	yes	`v-1.5` must inc metadata	Provide metadata
54	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 2	yes	as best practice 1 adding *descriptive metadata*	Provide descriptive metadata
55	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 3	yes	as best practice 1 adding *structural metadata*[^ie provide data dictionary ie code-book describing properties and datatypes and further use vocabularies and languagues for metadata]	Provide structural metadata
56	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 4	yes	`v-1.5` must be licensed	Provide data license information
57	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 5	yes	"`v-1.5` must inc provenance info[^ie sources of raw data and transformations thereof eg cleaning, standardising, validating, processing, etc]"	Provide data provenance information
58	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 6	yes	`v-1.5` must inc data quality info	Provide data quality information
59	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 7	yes	`v-1.5` must inc version indicator	Provide a version indicator
60	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 8	no	may not be possible as pre-`v-1.4` data not properly documented	Provide version history
61	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 9	yes	`v-1.5` must cite sources via URIs	Use persistent URIs as identifiers of datasets
62	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 10	yes	`v-1.5` and its sub-components must be citeable via URIs	Use persistent URIs as identifiers within datasets
63	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 11	yes	`v-1.5` and predecessors must be citeable as a whole via URIs	Assign URIs to dataset versions and series
64	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 12	yes	`v-1.5` must be machine-readable	Use machine-readable standardized data formats
65	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 13	yes	`v-1.5` must use location-neutral data values or types (when possible eg excluding text quotes)	Use locale-neutral data representations
66	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 14	yes	`v-1.5` must be available in vars formats	Provide data in multiple formats
67	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 15	yes	`v-1.5` must re-use standardised vocabularies	"Reuse vocabularies, preferably standardized ones"
68	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 16	yes	as best practice 15 adding *to an appropriate extent*	Choose the right formalization level
69	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 17	no	may not be possible as requires third-party	Provide bulk download
70	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 18	no	may not be possible as requires third-party	Provide Subsets for Large Datasets
71	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 19	no	may not be possible as requires third-party	Use content negotiation for serving data available in multiple formats
72	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 20	no	not relevant	Provide real-time access
73	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 21	no	not relevant	Provide data up to date
74	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 22	yes	`v-1.5` must inc information re missing values	Provide an explanation for data that is not available
75	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 23	no	may not be possible as requires third-party	Make data available through an API
76	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 24	no	may not be possible as requires third-party	Use Web Standards as the foundation of APIs
77	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 25	no	may not be possible as requires third-party	Provide complete documentation for your API
78	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 26	no	may not be possible as requires third-party	Avoid Breaking Changes to Your API
79	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 27	no	may not be possible as requires third-party	Preserve identifiers
80	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 28	yes	`v-1.5` must inc coverage info	Assess dataset coverage
81	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 29	no	not relevant	Gather feedback from data consumers
82	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 30	no	not relevant	Make feedback available
83	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 31	yes	`v-1.5` must inc generated data (if enriching)[^may not be needed]	Enrich data by generating new data
84	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 32	no	may not be possible as requires third-party	Provide Complementary Presentations
85	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 33	no	not relevant	Provide Feedback to the Original Publisher
86	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 34	yes	`v-1.5` must obey licences of sources employed in `work`	Follow Licensing Terms
87	W3C Data on the Web Best Practices	https://www.w3.org/TR/dwbp/	best practice 35	yes	`v-1.5` must cite sources	Cite the Original Publication
88	W3C Best Practices for Publishing Linked Data	http://www.w3.org/TR/ld-bp/	step 1	no	not relevant	Prepare stakeholders by explaining the process of creating and maintaining Linked Open Data
89	W3C Best Practices for Publishing Linked Data	http://www.w3.org/TR/ld-bp/	step 2	no	not relevant	Select a dataset that provides benefit to others for reuse
90	W3C Best Practices for Publishing Linked Data	http://www.w3.org/TR/ld-bp/	step 3	yes	`v-1.5` must be available in vars formats	Modeling Linked Data involves representing data objects and how they are related in an application-independent way
91	W3C Best Practices for Publishing Linked Data	http://www.w3.org/TR/ld-bp/	step 4	yes	`v-1.5` must be *appropriately* licensed	"Specify an appropriate open data license. Data reuse is more likely to occur when there is a clear statement about the origin, ownership and terms related to the use of the published data"
92	W3C Best Practices for Publishing Linked Data	http://www.w3.org/TR/ld-bp/	step 5	yes	URIs for `v-1.5` or its sub-components must be *appropriately* built	"The core of Linked Data is a well-considered URI naming strategy and implementation plan, based on HTTP URIs. Consideration for naming objects, multilingual support, data change over time and persistence strategy are the building blocks for useful Linked Data"
93	W3C Best Practices for Publishing Linked Data	http://www.w3.org/TR/ld-bp/	step 6	yes	`v-1.5` must re-use standardised vocabularies	"Describe objects with previously defined vocabularies whenever possible. Extend standard vocabularies where necessary, and create vocabularies (only when required) that follow best practices whenever possible"
94	W3C Best Practices for Publishing Linked Data	http://www.w3.org/TR/ld-bp/	step 7	yes	`v-1.5` must be available in `rdf` formats	Convert data to a Linked Data representation. This is typically done by script or other automated processes
95	W3C Best Practices for Publishing Linked Data	http://www.w3.org/TR/ld-bp/	step 8	no	may not be possible as requires third-party	Provide various ways for search engines and other automated processes to access data using standard Web mechanisms
96	W3C Best Practices for Publishing Linked Data	http://www.w3.org/TR/ld-bp/	step 9	no	not relevant	"Remember to announce new data sets on an authoritative domain. Importantly, remember that as a Linked Open Data publisher, an implicit social contract is in effect"
97	W3C Best Practices for Publishing Linked Data	http://www.w3.org/TR/ld-bp/	step 10	no	not relevant	Recognize your responsibility in maintaining data once it is published. Ensure that the dataset(s) remain available where your organization says it will be and is maintained over time
98	W3C Provenance XG Final Report	http://www.w3.org/2005/Incubator/prov/XGR-prov/	cat content dim object	yes	`v-1.5` must be citeable via URI	The artifact that a provenance statement is about
99	W3C Provenance XG Final Report	http://www.w3.org/2005/Incubator/prov/XGR-prov/	cat content dim attribution	yes	`v-1.5` must identify sources used and entities involved in `work`	The sources or entities that contributed to create the artifact in question
100	W3C Provenance XG Final Report	http://www.w3.org/2005/Incubator/prov/XGR-prov/	cat content dim process	yes	`v-1.5` must inc log details of `work`	The activities (or steps) that were carried out to generate or access the artifact at hand
101	W3C Provenance XG Final Report	http://www.w3.org/2005/Incubator/prov/XGR-prov/	cat content dim versioning	no	may not be possible as pre-`v-1.4` data not properly documented	Records of changes to an artifact over time and what entities and processes were associated with those changes
102	W3C Provenance XG Final Report	http://www.w3.org/2005/Incubator/prov/XGR-prov/	cat content dim justification	yes	as cat content dim process adding *inc reasoning or justification for decisions made during `work`*	Documentation recording why and how a particular decision is made
103	W3C Provenance XG Final Report	http://www.w3.org/2005/Incubator/prov/XGR-prov/	cat content dim entailment	no	not relevant	Explanations showing how facts were derived from other facts
104	W3C Provenance XG Final Report	http://www.w3.org/2005/Incubator/prov/XGR-prov/	cat management dim publication	no	may not be possible as requires third-party	Making provenance available on the Web
105	W3C Provenance XG Final Report	http://www.w3.org/2005/Incubator/prov/XGR-prov/	cat management dim access	no	may not be possible as requires third-party	The ability to find the provenance for a particular artifact
106	W3C Provenance XG Final Report	http://www.w3.org/2005/Incubator/prov/XGR-prov/	cat management dim dissemination	no	may not be possible as requires third-party	Defining how provenance should be distributed and its access be controlled
107	W3C Provenance XG Final Report	http://www.w3.org/2005/Incubator/prov/XGR-prov/	cat management dim scale	no	not relevant	Dealing with large amounts of provenance
108	W3C Provenance XG Final Report	http://www.w3.org/2005/Incubator/prov/XGR-prov/	cat use dim understanding	no	not relevant	How to enable the end user consumption of provenance
109	W3C Provenance XG Final Report	http://www.w3.org/2005/Incubator/prov/XGR-prov/	cat use dim interoperability	no	not relevant	Combining provenance produced by multiple different systems
110	W3C Provenance XG Final Report	http://www.w3.org/2005/Incubator/prov/XGR-prov/	cat use dim comparison	no	not relevant	Comparing artifacts through their provenance
111	W3C Provenance XG Final Report	http://www.w3.org/2005/Incubator/prov/XGR-prov/	cat use dim accountability	no	not relevant	Using provenance to assign credit or blame
112	W3C Provenance XG Final Report	http://www.w3.org/2005/Incubator/prov/XGR-prov/	cat use dim trust	no	not relevant	Using provenance to make trust judgments
113	W3C Provenance XG Final Report	http://www.w3.org/2005/Incubator/prov/XGR-prov/	cat use dim imperfections	no	not relevant	Dealing with imperfections in provenance records
114	W3C Provenance XG Final Report	http://www.w3.org/2005/Incubator/prov/XGR-prov/	cat use dim debugging	no	not relevant	Using provenance to detect bugs or failures of processes
115	OKF Frictionless Standards	https://specs.frictionlessdata.io/data-resource/	resource sec descriptor	no	json-specific	A Data Resource descriptor MUST be a valid JSON object
116	OKF Frictionless Standards	https://specs.frictionlessdata.io/data-resource/	resource sec data location	yes	`v-1.5` and sub-components must be geo-referenced	A resource MUST contain a property describing the location of the data associated to the resource
117	OKF Frictionless Standards	https://specs.frictionlessdata.io/data-resource/	resource sec metadata	yes	`v-1.5` and sub-components must inc metadata	A descriptor MUST contain a name property
118	OKF Frictionless Standards	https://specs.frictionlessdata.io/data-package/	package sec descriptor	no	json-specific	A Data Package descriptor MUST be a valid JSON object
119	OKF Frictionless Standards	https://specs.frictionlessdata.io/data-package/	package sec descriptor	yes	as package sec metadata adding *inc list and locations of sub-components of `v-1.5`*	The descriptor MUST contain a resources property describing the data resources
120	OKF Frictionless Standards	https://specs.frictionlessdata.io/data-package/	package sec resource information	no	json-specific	Packaged data resources are described in the resources property of the package descriptor. This property MUST be an array of objects. Each object MUST follow the Data Resource specification.
121	OKF Frictionless Standards	https://specs.frictionlessdata.io/data-package/	package sec metadata	yes	`v-1.5` must inc metadata	"The resources property is required, with at least one resource"
122	OKF Open Definition	https://opendefinition.org/od/2.1/en/	no 1.1	no	may not be possible (eg copyrighted material)	"The work must be in the public domain or provided under an open license (as defined in Section 2). Any additional terms accompanying the work (such as a terms of use, or patents held by the licensor) must not contradict the workâ€™s public domain status or terms of the license."
123	OKF Open Definition	https://opendefinition.org/od/2.1/en/	no 1.2	yes	`v-1.5` must be provided as a whole	"The work must be provided as a whole and at no more than a reasonable one-time reproduction cost, and should be downloadable via the Internet without charge. Any additional information necessary for license compliance (such as names of contributors required for compliance with attribution requirements) must also accompany the work."
124	OKF Open Definition	https://opendefinition.org/od/2.1/en/	no 1.3	yes	`v-1.5` must be machine-readable	The work must be provided in a form readily processable by a computer and where the individual elements of the work can be easily accessed and modified.
125	OKF Open Definition	https://opendefinition.org/od/2.1/en/	no 1.4	yes	`v-1.5` must be available in open formats	"The work must be provided in an open format. An open format is one which places no restrictions, monetary or otherwise, upon its use and can be fully processed with at least one free/libre/open-source software tool."
126	OKF Open Definition	https://opendefinition.org/od/2.1/en/	no 2.1.1	no	not relevant	`null`
127	OKF Open Definition	https://opendefinition.org/od/2.1/en/	no 2.1.2	no	not relevant	`null`
128	OKF Open Definition	https://opendefinition.org/od/2.1/en/	no 2.1.3	no	not relevant	`null`
129	OKF Open Definition	https://opendefinition.org/od/2.1/en/	no 2.1.4	no	not relevant	`null`
130	OKF Open Definition	https://opendefinition.org/od/2.1/en/	no 2.1.5	no	not relevant	`null`
131	OKF Open Definition	https://opendefinition.org/od/2.1/en/	no 2.1.6	no	not relevant	`null`
132	OKF Open Definition	https://opendefinition.org/od/2.1/en/	no 2.1.7	no	not relevant	`null`
133	OKF Open Definition	https://opendefinition.org/od/2.1/en/	no 2.1.8	no	not relevant	`null`
134	OKF Open Definition	https://opendefinition.org/od/2.1/en/	no 2.1.9	no	not relevant	`null`
135	OKF Open Definition	https://opendefinition.org/od/2.1/en/	no 2.2.1	no	not relevant	`null`
136	OKF Open Definition	https://opendefinition.org/od/2.1/en/	no 2.2.2	no	not relevant	`null`
137	OKF Open Definition	https://opendefinition.org/od/2.1/en/	no 2.2.3	no	not relevant	`null`
138	OKF Open Definition	https://opendefinition.org/od/2.1/en/	no 2.2.4	no	not relevant	`null`
139	OKF Open Definition	https://opendefinition.org/od/2.1/en/	no 2.2.5	no	not relevant	`null`
140	OKF Open Definition	https://opendefinition.org/od/2.1/en/	no 2.2.6	no	not relevant	`null`
141	OKF Open Definition	https://opendefinition.org/od/2.1/en/	no 2.2.7	no	not relevant	`null`
142	Mandakers & Dillon 2004	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/best-practices-with-large-databases-on-historical/docview/231968382/se-2?accountid=11311	A1	yes	`v-1.5` must inc *clear* aim and content details	"The universe of the database-in other words, the goal and content of the database considered together-should be defined very clearly. If a particular source, such as a census, is chosen to form the core of the database, the rationale behind this choice should be documented."
143	Mandakers & Dillon 2004	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/best-practices-with-large-databases-on-historical/docview/231968382/se-2?accountid=11311	A2	no	`v-1.5` must inc details re primary sources used in `work`[^may not be possible as pre-`v-1.4` data not properly documented]	"The type of primary source to be transformed into machine-readable format will be primarily dependent on the universe of the database and the availability of sources. In principle, all available information recorded in the source should be included in the database. Database creators may choose to omit certain variables to save data-entry time and/or money. However, such choices should be evaluated against the possible future cost of restoring omitted variables. The motivation for choosing each source should be documented extensively."
144	Mandakers & Dillon 2004	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/best-practices-with-large-databases-on-historical/docview/231968382/se-2?accountid=11311	A3	no	as A2 adding *extensive details*[^may not be possible as pre-`v-1.4` data not properly documented]	The documentation of each source should include at least the elements a-i.
145	Mandakers & Dillon 2004	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/best-practices-with-large-databases-on-historical/docview/231968382/se-2?accountid=11311	A4	no	not relevant	"If the database or its component parts comprise a sample, the rules and recommendations a-d shall be applied."
146	Mandakers & Dillon 2004	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/best-practices-with-large-databases-on-historical/docview/231968382/se-2?accountid=11311	B1	yes	`work-files` must be editable	"It must always be possible to make corrections in the source component(s) of the database. A database continually evolves as additional data are linked to it. During this process, one should be able to resolve ambiguous values by correcting one or more of the source components. These procedures should include the correction of mistakes, such as event-date errors, discovered when one links additional data."
147	Mandakers & Dillon 2004	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/best-practices-with-large-databases-on-historical/docview/231968382/se-2?accountid=11311	B2	no	"`work-files` must distinguish raw data values (literally transcribed from source) from standardised, cleaned or processed values (generated from raw data values)[^may not be possible as pre-`v-1.4` data not properly documented]"	The processes of standardization and integration should be iterative. These repeating procedures are made possible only by preserving a clear distinction between the literal transcription of the data in the source and the standardized version of the data in the central database. Changes in the source components or in tables with standard values can automatically or semi-automatically lead to changes in the contents of the central database. This distinction also makes it possible to systematize the release of different versions of the data. Database creators may choose to release different versions of the data not only because standards or procedures in resolving data inconsistencies evolve over time but also because the methods of standardizing or integrating data may be dependent upon the specific goal of a particular research project or publication.
148	Mandakers & Dillon 2004	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/best-practices-with-large-databases-on-historical/docview/231968382/se-2?accountid=11311	B3	no	`work-files` must inc rules or procedures followed for integrating data values from disparate sources during `work`[^may not be possible as pre-`v-1.4` data not properly documented]	"The rules by which data from different sources are integrated should be documented. This recommendation applies to datasets that link information about individuals and family members to construct unique biographies and reconstitute families; it also applies to all other linked information, such as contextual economic or geographic information."
149	Mandakers & Dillon 2004	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/best-practices-with-large-databases-on-historical/docview/231968382/se-2?accountid=11311	B4	no	`work-files` must standardise spelling	"To standardize the spelling of values drawn from different sources, the following conventions are recommended. Spelling standards in the central database and data releases will be set primarily by data drawn from higher-quality primary sources, such as vital acts, and, second, from lower-quality sources such as population registers or tax records. In the case of spelling inconsistencies between sources of the same quality, the standard could be set by the most recent source; for example, spelling used in death-certificate data could prevail over spelling used in birth-certificate data."
150	Mandakers & Dillon 2004	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/best-practices-with-large-databases-on-historical/docview/231968382/se-2?accountid=11311	B5	no	`v-1.5` must clealy flag manually corrected data values[^may not be possible as pre-`v-1.4` data not properly documented]	"The decisions by which database creators make case-by-case manual corrections of mistakes in the original source (errors or discrepancies of the nature discussed previously in items 1 and 3a) should be clearly documented in the sources component itself by preserving the clearly marked original text or figure. Preserving the original text enables researchers to make a different interpretation. Data-transcription forms and data-entry software should include comment fields so that transcribers and data-entry operators have the opportunity to clarify their manual corrections. All manual corrections are undertaken in the sources files; in the central database, only automatic corrections are made by applying rules designed to correct source-based mistakes."
151	Mandakers & Dillon 2004	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/best-practices-with-large-databases-on-historical/docview/231968382/se-2?accountid=11311	B6	no	`v-1.5` must clearly flag generated or inferred or estimated data values[^may not be possible as pre-`v-1.4` data not properly documented]	"Data inferred by means of logic or estimation should be stored in a different variable or identified by a flag variable. The manner in which such inferences are made should be recorded. This documentation is especially important in the case of dating the data for particular research methods such as event-history analysis. Whereas in many cases, the primary source does not provide a specific date, it is often possible to make an educated guess. As it is for other kinds of inferred data, estimations of dates should be standardized. If different rules of inference are applied to the same variable, an additional variable is needed to describe the rules by which the dates were estimated or inferred."
152	Mandakers & Dillon 2004	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/best-practices-with-large-databases-on-historical/docview/231968382/se-2?accountid=11311	B7	no	sources or resources or materials used in `pre-git-work` and `work` must be preserved[^may not be possible]	"All electronic material relating to the database should be stored, preserved, and made obtainable in the simplest format possible whether or not it is also released in proprietary software formats such as Microsoft Access, SPSS, and SAS. The choice of character set should be documented."
153	Mandakers & Dillon 2004	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/best-practices-with-large-databases-on-historical/docview/231968382/se-2?accountid=11311	B8	yes	`work-files` must be archived	"To prevent data losses, the user should back up working files at regular intervals. In addition, a copy of the whole dataset should be preserved in a disaster-proof environment, namely, a data archive such as the Interuniversity Consortium for Political and Social Research (ICPSR) or the UK Data Archive."
154	Mandakers & Dillon 2004	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/best-practices-with-large-databases-on-historical/docview/231968382/se-2?accountid=11311	C1	no	not relevant	"Rules laid by national and supranational data-protection acts must be respected and honored. The rules concerning the database in question should and can be made public, for example, if one publishes the constitution whereby the data were gathered and released."
155	Mandakers & Dillon 2004	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/best-practices-with-large-databases-on-historical/docview/231968382/se-2?accountid=11311	C2	no	not relevant	"Releases of all or part of the dataset should be accompanied by, at minimum, the release name and release date. If the release name is not unique, a serial number must be added as well. These features must be included in all tables and files the release comprises. The correct manner for citing the dataset in journals should also be made explicit. New versions of existing releases should highlight the changes that have been made since the previous one."
156	Mandakers & Dillon 2004	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/best-practices-with-large-databases-on-historical/docview/231968382/se-2?accountid=11311	C3	no	not relevant	"Provision should be made for broad public access to the data, either at no cost or limited to handling charges. To comply with confidentiality laws, it may be necessary to provide the data in an anonymized format, in which case the documentation should both state that information has been removed from the data release as well as describe which information has been removed. Anonymization of data is particularly important in the case of databases that include information about the causes of death or that cover the complete life course of individuals and families who span both historical and contemporary periods. In such instances, the recommendation is to anonymize all cases less than one hundred years old, even if there are no legal objections against full publication."
157	Mandakers & Dillon 2004	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/best-practices-with-large-databases-on-historical/docview/231968382/se-2?accountid=11311	C4	no	not relevant	"Data may be distributed freely or through specified contracts with individual users. When the database is not freely distributed, conditions on the use of data will be regulated by contract. If the released dataset is freely distributed by the institution, users are not allowed to (a) disseminate altered versions of the data or make additions without consulting the administrators of the database, or (b) charge fees for use or distribution; users should (c) cite the database according to the conditions of use and (d) send a copy of all publications, research reports, or educational material based on the dataset to the owners of the license."
158	Mandakers & Dillon 2004	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/best-practices-with-large-databases-on-historical/docview/231968382/se-2?accountid=11311	C5	yes	variables or properties or relations or edges within `v-1.5` must be standardised	"Variables should be standardized as much as possible without losing content. Standardization should be effected in such a way that original values are retained and new ones are kept in separate variables or tables. Wherever possible, releases should include, at the minimum, the internationally standardized versions of certain complex variables, such as occupation and birthplace."
159	Mandakers & Dillon 2004	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/best-practices-with-large-databases-on-historical/docview/231968382/se-2?accountid=11311	C6	yes	missing data values ie vertices within `v-1.5` must be explained	"The reasons for missing data should be explained. Numbers such as ""0"" and ""99,"" which are meaningful in certain contexts such as age, should not be used to indicate missing information. Instead, negative codes should be used. The following four codes are recommended as standard values for lacking information: -1 not available in the source, -2 not readable in the source, -3 not available for reasons of privacy, but existing in the database, -4 for reasons of privacy, not taken into the database. Other negative codes can be used for reasons specified in the documentation."
160	Mandakers & Dillon 2004	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/best-practices-with-large-databases-on-historical/docview/231968382/se-2?accountid=11311	C7	yes	geographic data values within `v-1.5` must be geo-referenced	All geographic information should be suitably georeferenced to make it possible to relate the data to Geographic Information Systems.
161	Mandakers & Dillon 2004	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/best-practices-with-large-databases-on-historical/docview/231968382/se-2?accountid=11311	C8	no	not relevant	"To assist researchers unfamiliar with research designs featuring statistical tests, releases should refer to model studies that employ the dataset or similar data."
162	Mandakers & Dillon 2004	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/best-practices-with-large-databases-on-historical/docview/231968382/se-2?accountid=11311	C9	yes	`v-1.5` must be *easily* human-readable	"To encourage researchers unfamiliar with large databases, ""easy-user versions"" of existing releases should also be produced."
163	Mandakers & Dillon 2004	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/best-practices-with-large-databases-on-historical/docview/231968382/se-2?accountid=11311	C10	no	DDI-specific	"The Data Documentation Initiative (DDI) developed by the ICPSR and participating institutions such as Networked Social Science Tools and Resources (NESSTAR) should be adopted to guide the development of metadata, or online documentation. The use of DDI will ensure that metadata have been produced ""in a uniform, highly structured format that is easily and precisely searchable on the Web, that lends itself well to simultaneous use of multiple datasets, and that will significantly improve the content and usability of metadata"" (DDI 2002)."
164	Mandakers & Dillon 2004	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/best-practices-with-large-databases-on-historical/docview/231968382/se-2?accountid=11311	C11	no	not relevant	"Besides the already-mentioned documentation in A3 and B3, the Web site of the database should include the elements a-o."
165	Mandakers & Dillon 2004	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/best-practices-with-large-databases-on-historical/docview/231968382/se-2?accountid=11311	C12	no	not relevant	"To stimulate interest among potential users, information about the progress of the database should be published on the Web site at regular intervals. Such reports can consist of updates on the number of cases entered into the database or the extent to which data have been coded and prepared for release. Beginning with the first release of the database, its documentation must be published on the Web site."
166	Hoekstra & Koolen 2019	https://doi-org.ezp-prod1.hul.harvard.edu/10.1080/01615440.2018.1484676	sec 1 para 4	yes	"`work-files` must inc *explicit descriptions* of data-transforming activities undertaking during `work`[^inc data source selection, modelling data, normalisation ie standardising data, classification ie grouping of data values or vertices, and linking ie establishing relations between data values or vertices]"	"Transparency of approach, whether digital or analogue, requires describing the activities that constitute that approach, and how they are combined in a process to generate new knowledge or ways of seeing. We argue that there is a relatively short list of activities that make up most digital research methods, and that to achieve transparency, it is important to understand the nature of these activities. The types of data transforming activities that should be brought to the surface in presenting historical research are: selection, modelling, normalization, classifying, and linking."
167	Hoekstra & Koolen 2019	https://doi-org.ezp-prod1.hul.harvard.edu/10.1080/01615440.2018.1484676	sec 1 para 6	yes	`work-files` must be archived	"Several digital historians deposit software and scripts used in their research on GitHub for others to scrutinize and reuse. While this is an important step, additional description and especially methodological argumentation is needed to arrive at a coherent and commonly understood set of methods for doing digital history."
168	Hoekstra & Koolen 2019	https://doi-org.ezp-prod1.hul.harvard.edu/10.1080/01615440.2018.1484676	sec 1 para 6	yes	as sec 1 para 4 adding *and reasoning or justification of data-transforming activities*	"Several digital historians deposit software and scripts used in their research on GitHub for others to scrutinize and reuse. While this is an important step, additional description and especially methodological argumentation is needed to arrive at a coherent and commonly understood set of methods for doing digital history."
169	IDS at Maastricht Univ IDS Best Practices	https://maastrichtu-ids.github.io/best-practices/docs/	cat management sec administration	yes	`work-files` must be archived	When starting a Data Science project you need to create a repository on a platform to host your project's code.
170	IDS at Maastricht Univ IDS Best Practices	https://maastrichtu-ids.github.io/best-practices/docs/	cat management sec administration	no	not relevant	"Using issues is a great way to keep track of feedbacks, bugs and improvements to do to your project. We encourage you to use them as much as possible."
171	IDS at Maastricht Univ IDS Best Practices	https://maastrichtu-ids.github.io/best-practices/docs/	cat management sec administration	no	not relevant	Code-hosting platforms enable to define different user access to your code repository.
172	IDS at Maastricht Univ IDS Best Practices	https://maastrichtu-ids.github.io/best-practices/docs/	cat management sec administration	no	not relevant	"Additionally, for some projects you might need a public chat channel."
173	IDS at Maastricht Univ IDS Best Practices	https://maastrichtu-ids.github.io/best-practices/docs/	cat management sec FAIR	yes	as cat management sec administration adding *archived in repositories which ensure data persistence*	"Data repositories, such as Figshare, Zenodo, DataDryad, Kaggle Datasets and many others, are a good way to ensure dataset persistence."
174	IDS at Maastricht Univ IDS Best Practices	https://maastrichtu-ids.github.io/best-practices/docs/	cat management sec FAIR	yes	`v-1.5` must in provenance details	"Provenance: with datasets often published in multiple repositories, it would be useful for repositories to describe the provenance information more explicitly in the metadata. The provenance information helps users understand who collected the data, where the primary source of the dataset is, or how it might have changed. The PROV ontology can be used."
175	IDS at Maastricht Univ IDS Best Practices	https://maastrichtu-ids.github.io/best-practices/docs/	cat management sec FAIR	yes	`v-1.5` must be licensed	"datasets should include licensing information, ideally in a machine-readable format."
176	IDS at Maastricht Univ IDS Best Practices	https://maastrichtu-ids.github.io/best-practices/docs/	cat management sec FAIR	yes	`v-1.5` must be citeable via URI	"Assigning persistent identifiers, such as DOIs (Digital Object Identifier), is critical for long-term tracking and useability."
177	IDS at Maastricht Univ IDS Best Practices	https://maastrichtu-ids.github.io/best-practices/docs/	cat management sec FAIR	yes	`v-1.5` must inc details re compliance with FAIR Guiding Principles	Assessing your data FAIRness
178	IDS at Maastricht Univ IDS Best Practices	https://maastrichtu-ids.github.io/best-practices/docs/	cat development sec environment	yes	`work` should ie may use Docker to run programmes	"Using Docker comes with lot of advantages, one of the most prominent ones being the ability to run programs in an environment that is always the same (and thus, no more 'it works on my laptop' issues). Consider using Docker to run existing third party software on your laptop, to share your program with others, or to run your application on a remote server."
179	IDS at Maastricht Univ IDS Best Practices	https://maastrichtu-ids.github.io/best-practices/docs/	cat development sec environment	yes	`work` should ie may use Homebrew to manage programming libraries	Consider using Conda environments to make managing libraries for different programming languages easier. Be wary of the difference between pip and Conda if you do.
180	IDS at Maastricht Univ IDS Best Practices	https://maastrichtu-ids.github.io/best-practices/docs/	cat development sec environment	yes	`work` should ie may use Terminal ie line interface	The terminal is the interface with which you can execute text based commands. We recommend getting a basic familiarity to at least be able to navigate the folder structure and run shell commands.
181	IDS at Maastricht Univ IDS Best Practices	https://maastrichtu-ids.github.io/best-practices/docs/	cat development sec code management	yes	`work` should ie may use Git for version control	The most important step to managing your code is to save it in a manner that will allow a version history as well as collaboration with others. The current standard for this is to use Git.
182	IDS at Maastricht Univ IDS Best Practices	https://maastrichtu-ids.github.io/best-practices/docs/	cat development sec publishing code	no	not relevant	The best way to share your work is to use existing frameworks to publish your code in a manner that is easily run by other researchers.
183	IDS at Maastricht Univ IDS Best Practices	https://maastrichtu-ids.github.io/best-practices/docs/	cat development sec repository	no	not relevant	Take some time to See how to define user access to your repository when created in the MaastrichtU-IDS GitHub organization.
184	IDS at Maastricht Univ IDS Best Practices	https://maastrichtu-ids.github.io/best-practices/docs/	cat development sec repository	yes	`work-files` must be licensed	Adding a license file is mandatory as no one is allowed to legally use your code if no license is included. The default choice for software should be the MIT license
185	IDS at Maastricht Univ IDS Best Practices	https://maastrichtu-ids.github.io/best-practices/docs/	cat development sec repository	no	DOAP-specific	"If you want your project listed on the IDS projects website, add a DOAP file to the root of the git repository."
186	IDS at Maastricht Univ IDS Best Practices	https://maastrichtu-ids.github.io/best-practices/docs/	cat development sec integration	no	not relevant	"Continuous integration and continuous delivery/deployment involves automating all possible processes in your development cycle, such as testing or deploying. This should be considered when you are expecting to work on a codebase for an extended amount of time or with a group of people in order to save time in the long run. The choice of CI/CD technology depends on the platform you are using to store your code. We strongly recommend you to define Continuous Integration if you wrote tests for your application or regularly need to publish some packages."
187	IDS at Maastricht Univ IDS Best Practices	https://maastrichtu-ids.github.io/best-practices/docs/	cat development sec documentation	yes	`work-files` must inc *well-written* readme file	"For most projects a simple well-written README.md is enough documentation, and it will greatly improve the exposure and re-usability of your code."
188	IDS at Maastricht Univ IDS Best Practices	https://maastrichtu-ids.github.io/best-practices/docs/	cat development sec ontologies	yes	`work-files` must re-use existing ontologies ie vocabularies	"You will need to define the class and relations for the properties in your data. The easiest way is to find classes and properties in existing model (aka. ontologies). Some properties are standard like rdf:type and rdfs:label, but for more specific concepts the best is to find an existing data model matching your model."
189	IDS at Maastricht Univ IDS Best Practices	https://maastrichtu-ids.github.io/best-practices/docs/	cat development sec ontologies	no	SHACL-specific	"In the case you are reusing existing ontologies the best is to define the schema your data will follow using SHACL shapes, or ShEx expressions. This will allow you to validate the generated data, and other users will be able to quickly understand your data."
190	IDS at Maastricht Univ IDS Best Practices	https://maastrichtu-ids.github.io/best-practices/docs/	cat development sec ontologies	yes	`work-files` must be citeable via persistent URIs	"Use pesistent identifier. We recommend to use the w3id.org system, as it allows any GitHub user to define and reserve your persistent namespace for free in a few minutes."
191	IDS at Maastricht Univ IDS Best Practices	https://maastrichtu-ids.github.io/best-practices/docs/	cat resources sec projects	no	not relevant	IDS projects that are stored at your personal Github can be also added to IDS Dashboard.
192	FAIR Guiding Principles	https://www.go-fair.org/fair-principles/	F1	yes	`v-1.5` and its sub-components must be citeable via *globally unique and persistent* URIs	(meta)data are assigned a globally unique and persistent identifier
193	FAIR Guiding Principles	https://www.go-fair.org/fair-principles/	F2	yes	`v-1.5` must inc *rich* metadata	data are described with rich metadata (defined by R1 below)
194	FAIR Guiding Principles	https://www.go-fair.org/fair-principles/	F3	yes	metadata files in `v-1.5` must identify the resource they describe via URIs	metadata clearly and explicitly include the identifier of the data it describes
195	FAIR Guiding Principles	https://www.go-fair.org/fair-principles/	F4	no	`v-1.5` must be findable ie indexable by search engine[^may not be possible as requires third-party]	(meta)data are registered or indexed in a searchable resource
196	FAIR Guiding Principles	https://www.go-fair.org/fair-principles/	A1	no	URIs of `v-1.5` and sub-components must use non-specialised and non-proprietary schemes[^eg http]	(meta)data are retrievable by their identifier using a standardized communications protocol
197	FAIR Guiding Principles	https://www.go-fair.org/fair-principles/	A1.1	no	as A1 adding *no-cost and open-sourced schemes*[^eg http]	"the protocol is open, free, and universally implementable"
198	FAIR Guiding Principles	https://www.go-fair.org/fair-principles/	A1.2	no	as A1 adding *inc schemes allowing for authentication or authorisation where needed*[^eg https]	"the protocol allows for an authentication and authorization procedure, where necessary"
199	FAIR Guiding Principles	https://www.go-fair.org/fair-principles/	A2	no	may not be possible as requires third-party	"metadata are accessible, even when the data are no longer available"
200	FAIR Guiding Principles	https://www.go-fair.org/fair-principles/	I1	yes	`v-1.5` must be machine-readable[^ie use standardies vocabs ie ontologies and use a well-defined framework to describe and structure data and metadata eg rdf]	"(meta)data use a formal, accessible, shared, and broadly applicable language for knowledge representation."
201	FAIR Guiding Principles	https://www.go-fair.org/fair-principles/	I2	no	`v-1.5` must re-use FAIR-compliant vocabularies[^may not be possible as unsure of which vocabs are FAIR-compliant]	(meta)data use vocabularies that follow FAIR principles
202	FAIR Guiding Principles	https://www.go-fair.org/fair-principles/	I3	no	properties or relations among data values ie edges within `v-1.5` should be specific or rich[^eg *x is a regulator of y* rather than *x is associated with y*]	(meta)data include qualified references to other (meta)data
203	FAIR Guiding Principles	https://www.go-fair.org/fair-principles/	R1	yes	as F2 adding *inc vars accurate and relevant attributes*	meta(data) are richly described with a plurality of accurate and relevant attributes
204	FAIR Guiding Principles	https://www.go-fair.org/fair-principles/	R1.1	yes	`v-1.5` must be *appropriately* licensed[^ie clear and accessible licence]	(meta)data are released with a clear and accessible data usage license
205	FAIR Guiding Principles	https://www.go-fair.org/fair-principles/	R1.2	yes	`v-1.5` must inc detailed provenance	(meta)data are associated with detailed provenance
206	FAIR Guiding Principles	https://www.go-fair.org/fair-principles/	R1.3	yes	"`v-1.5` must meet domain-specific metadata standards[^eg http://schema.datacite.org/, http://dublincore.org/specifications/, https://www.iso.org/standard/53798.html, http://www.ddialliance.org/Specification/]"	(meta)data meet domain-relevant community standards
207	Panton Principles	http://www.pantonprinciples.org	no 1	no	`v-1.5` must inc details regarding author wishes[^not relevant]	When publishing data make an explicit and robust statement of your wishes.
208	Panton Principles	http://www.pantonprinciples.org	no 2	no	`v-1.5` must inc data-specific licence[^may not be possible]	Use a recognized waiver or license that is appropriate for data.
209	Panton Principles	http://www.pantonprinciples.org	no 3	no	`v-1.5` must meet OKF Open Definition[^may not be possible]	If you want your data to be effectively used and added to by others it should be open as defined by the Open Knowledge/Data Definition â€“ in particular non-commercial and other restrictive clauses should not be used.
210	Panton Principles	http://www.pantonprinciples.org	no 4	no	`v-1.5` must be entered into public domain[^may not be possible]	Explicit dedication of data underlying published science into the public domain via PDDL or CCZero is strongly recommended and ensures compliance with both the Science Commons Protocol for Implementing Open Access Data and the Open Knowledge/Data Definition.
211	APS Psychological Science Submission Guidelines	http://www.psychologicalscience.org/publications/psychological_science/ps-submissions	sec open practices subsec 1	no	`pre-git-work` and `work` must be pre-registered[^not possible for `pre-git-work`]	"To promote replicability and transparency, Psychological Science strongly encourages authors to preregister their studies and, when possible, to do so before data collection."
212	APS Psychological Science Submission Guidelines	http://www.psychologicalscience.org/publications/psychological_science/ps-submissions	sec open practices subsec 2	yes	`pre-git-files` and `work-files` must be archived and licensed	"Authors are strongly encouraged to make their data, analysis/code, and materials available to reviewers during the peer review process and, should the article be accepted, publicly accessible to readers."
213	APS Psychological Science Submission Guidelines	http://www.psychologicalscience.org/publications/psychological_science/ps-submissions	sec open practices subsec 3	no	not relevant	"Each manuscript reporting new empirical work must include an Open Practices Statement that indicates whether the study (or studies) reported were preregistered and whether the data, analysis/code, and/or materials are available on a permanent third-party archive (or are included in Supplemental Materials)."
214	FOSTER Open Science Training Handbook	https://open-science-training-handbook.gitbook.io/book/	null	no	not standards	`null`
215	AHA Statement on Standards of Professional Conduct 1987-2019	https://www.historians.org/jobs-and-professional-development/statements-standards-and-guidelines-of-the-discipline/statement-on-standards-of-professional-conduct#SharedValues	null	no	language too vague	`null`
216	NCPH Code of Ethics and Professional Conduct 2007	https://ncph.org/about/governance-committees/code-of-ethics-and-professional-conduct/	null	no	language too vague	`null`
217	Broman & Woo 2018	https://doi.org/10.1080/00031305.2017.1375989	null	no	csv-specific	`null`
218	Robertson & Mullen 2021	https://doi.org/10.1093/jsh/shab015	null	no	not standards	`null`
219	Library Carpentry Top 10 FAIR Data & Software Things for Humanities: Historical Research	https://librarycarpentry.org/Top-10-FAIR/2018/12/01/historical-research/	thing 1	yes	`work-files` must be archived	"Data repositories enable researchers to share their data sets. The following data repositories accept data sets in the field of history: DANS EASY, Figshare, Zenodo, B2SHARE. A number of additional data repositories can be found by going to re3data.org, and by clicking on Browse > Browse by subject > History."
220	Library Carpentry Top 10 FAIR Data & Software Things for Humanities: Historical Research	https://librarycarpentry.org/Top-10-FAIR/2018/12/01/historical-research/	thing 2	yes	`v-1.5` must inc metadata	"Once a certain data repository has been selected, the data set can be submitted, together with the metadata describing this data set."
221	Library Carpentry Top 10 FAIR Data & Software Things for Humanities: Historical Research	https://librarycarpentry.org/Top-10-FAIR/2018/12/01/historical-research/	thing 3	yes	`v-1.5` must be citeable via *persistent* URI	"Datasets need to be deposited in repositories that assign persistent identifiers (PIDs) to ensure that online references to publications, research data, and persons remain available in the future."
222	Library Carpentry Top 10 FAIR Data & Software Things for Humanities: Historical Research	https://librarycarpentry.org/Top-10-FAIR/2018/12/01/historical-research/	thing 4	no	`v-1.5` must meet FAIR A1[^may not be possible]	The FAIR principles stipulate that data and metadata ought to be â€œretrievable by their identifier using a standardised communication protocolâ€ (requirement A1). This requirement does not necessarily imply that the data should fully be available in open access. It principally means that there needs to be a protocol that users may follow to obtain of the data set.
223	Library Carpentry Top 10 FAIR Data & Software Things for Humanities: Historical Research	https://librarycarpentry.org/Top-10-FAIR/2018/12/01/historical-research/	thing 5	yes	`v-1.5` must be well-structured and well-organised[^eg must follow csv-dialect and csv best practices eg as per Broman & Woo 2018 and must inc data dictionary]	Well-structured and well-organised data can evidently be reused much more easily. This section explains how researchers can organize their data in such a way that they can be analysed effectively with data science tools. Many historians capture their data in spreadsheets.
224	Library Carpentry Top 10 FAIR Data & Software Things for Humanities: Historical Research	https://librarycarpentry.org/Top-10-FAIR/2018/12/01/historical-research/	thing 6	yes	`v-1.5` must re-use standardised vocabularies	"As a first step, it can be useful to explore whether some of the general topics that you focus on have already been assigned persistent identifiers or URIs. Many researchers and institutions have developed shared vocabularies and ontologies to standardise terminology. In many cases, the terms which have been defined have also been assigned persistent identifiers. Such shared vocabularies can make it clear that we are talking about the same thing when we exchange knowledge."
225	Library Carpentry Top 10 FAIR Data & Software Things for Humanities: Historical Research	https://librarycarpentry.org/Top-10-FAIR/2018/12/01/historical-research/	thing 7	yes	`v-1.5` must be available in `rdf` formats	"More concretely, it implies that you record your data using the Resource Description Framework (RDF) format."
226	Library Carpentry Top 10 FAIR Data & Software Things for Humanities: Historical Research	https://librarycarpentry.org/Top-10-FAIR/2018/12/01/historical-research/	thing 8	yes	`v-1.5` must be licensed	A license describes the conditions under which your data or software is (re)usable. 
227	Library Carpentry Top 10 FAIR Data & Software Things for Humanities: Historical Research	https://librarycarpentry.org/Top-10-FAIR/2018/12/01/historical-research/	thing 9	yes	`work-files` must *appropriately* cite sources	"When you have made use of someone elseâ€™s data, you are strongly recommended to attribute the original creators of these data by including a proper reference."
228	Library Carpentry Top 10 FAIR Data & Software Things for Humanities: Historical Research	https://librarycarpentry.org/Top-10-FAIR/2018/12/01/historical-research/	thing 10	no	not relevant	"Policies for data availability can come from publishers, funders and universities. These policies are listed on the respective website, but finding these is not always straightforward."
229	Data Carpentry Data Organization in Spreadsheets for Ecologists	https://datacarpentry.org/spreadsheet-ecology-lesson/	null	no	csv-specific	`null`
230	DDI Lifecycle	https://ddialliance.org/Specification/DDI-Lifecycle/3.3/	null	no	xml-specific	`null`
231	ICADL 2016 cap Krataithong et al 2016	https://link-springer-com.ezp-prod1.hul.harvard.edu/chapter/10.1007/978-3-319-49304-6_31	null	no	"csv-specific, rdf-specific or not standards "	conference paper presented 2016 showing csv to rdf conversion though does not cover the full process in detail
232	IDS at Maastricht Univ Build a FAIR Knowledge Graph	https://maastrichtu-ids.github.io/best-practices/blog/2021/03/18/build-a-kg/	null	no	"csv-specific, rdf-specific or not standards "	non-journal article by non-profit institute showing csv to rdf via YARRRML-based programme [Matey](https://rml.io/yarrrml/matey)
233	Binding et al 2021	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/migrating-complex-classification-scheme-semantic/docview/2543608213/se-2?accountid=11311	null	no	"csv-secific, skos-specific or not standards"	journal article pub 2021 showing csv to skos conversion via .NET-based [STELETO](https://github.com/cbinding/STELETO/) transformation tool
234	Lee et al 2021	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/rdfizing-biosynthetic-pathway-i-e-coli-o-antigen/docview/2611239195/se-2	null	no	"csv-specific, rdf-specific or not standards "	journal article pub 2021 showing csv to rdf conversion via standardising data-values in defined programming-language -> manually creating URIs via third-party -> input csv into Python-based converter called [RDFLib](https://gitlab.com/lsunmyoung/rdfization) -> get rdf in Turtle dialect -> validate output via SPARQL
235	Crotti Jr et al 2017	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/evaluation-uplift-mapping-languages/docview/1966401153/se-2?accountid=11311	null	no	"csv-specific, rdf-specific or not standards "	journal article pub 2017 showing csv to rdf conversion via algorithm written in `null` called FunUL though could not locate this in github nor elsewhere online as of 14 aug 2022
236	Garcia-Gonzalez et al 2020	http://search.proquest.com.ezp-prod1.hul.harvard.edu/scholarly-journals/shexml-improving-usability-heterogeneous-data/docview/2463305655/se-2	null	no	"xml-specific, json-specific, rdf-specific or not standards"	journal article pub 23 nov 2020 showing xml + json to rdf but listed vars standard translation ie transformation algorithms in pages 3-6
237	Chaves-Fraga et al 2020	https://www.semantic-web-journal.net/content/enhancing-virtual-ontology-based-access-over-tabular-data-morph-csv-0	null	no	"csv-specific, sql-specific, rdf-specific or not standards "	preprint article pub 11 jun 2020 or 6 nov 2020 showing csv to sql to rdf via algorithm written in SPARQL and named [Morph-CSV](https://morph.oeg.fi.upm.es/tool/morph-csv) //this seems well-documented and tested as of 14 aug 2022 18.02
238	Swirrl CSV on the Web	https://csvw.org/	null	no	"csv-specific, rdf-specific or not standards "	non-journal article by UK for-profit Swirrl recommending csv to rdf conversion via metadata manually created inc first- and third-party URIs -> input csv and json into a [validator or converter](https://csvw.org/tools.html) -> validate -> convert to rdf
239	Mahmud et al 2018	http://www.jatit.org/volumes/Vol96No20/19Vol96No20.pdf	null	no	"csv-specific, rdf-specific or not standards "	journal article pub 31 oct 2018 showing csv to rdf via three algorithms ie cvs is parsed -> embedded metadata created or approximated in json -> data converted to rdf where algorithms written in Java and named CSV2RDF though name is ambiguous as of 14 aug 2022
240	Awesome Semantic Web	https://github.com/semantalytics/awesome-semantic-web/blob/master/README.md	null	no	not standards	A curated list of various semantic web and linked data resources
241	Tennison Linked CSV	https://github.com/JeniT/linked-csv	null	no	csv-specific	`null`
242	Programming Historian	http://programminghistorian.org/en/about	null	no	not standards	"In 2012, Programming Historian expanded its editorial team and launched as an open access peer reviewed scholarly journal of methodology for digital historians."
243	UK Data Archive sec Managing data subsec Standards and procedures	https://www.data-archive.ac.uk/managing-data/standards-and-procedures/	null	no	`null`	`null`
244	W3C Spatial Data on the Web Best Practices	https://www.w3.org/TR/sdw-bp/	null	no	`null`	re spatial data values
245	W3C CSV on the Web: A Primer	https://www.w3.org/TR/tabular-data-primer/	null	no	csv-specific	`null`
246	W3C Model for Tabular Data and Metadata on the Web	https://www.w3.org/TR/tabular-data-model/	null	no	csv-specific	`null`
247	W3C Generating JSON from Tabular Data on the Web	https://www.w3.org/TR/2015/REC-csv2json-20151217/	null	no	"json-specific, csv-specific"	`null`
248	W3C Generating RDF from Tabular Data on the Web	http://www.w3.org/TR/csv2rdf/	null	no	"rdf-specific, csv-specific"	`null`
249	W3C Metadata Vocabulary for Tabular Data	https://www.w3.org/TR/2015/REC-tabular-metadata-20151217/	null	no	csv-specific	`null`
250	W3C A Direct Mapping of Relational Data to RDF	http://www.w3.org/TR/rdb-direct-mapping/	null	no	"sql-specific, rdf-specific"	`null`
251	W3C R2RML: RDB to RDF Mapping Language	http://www.w3.org/TR/r2rml/	null	no	"sql-specific, rdf-specific"	`null`
252	W3C Cool URIs for the Semantic Web	http://www.w3.org/TR/cooluris/	null	no	`null`	re URIs
253	W3C Linked Data Platform Best Practices and Guidelines	http://www.w3.org/TR/ldp-bp/	null	no	`null`	`null`
254	W3C Linked Data Glossary	http://www.w3.org/TR/ld-glossary/	null	no	not standards	`null`
255	OKF CSV Dialect	https://specs.frictionlessdata.io/csv-dialect/	null	no	csv-specific	`null`
256	OKF Table Schema	https://specs.frictionlessdata.io/table-schema/	null	no	csv-specific	`null`
257	OKF Tabular Data Resource	https://specs.frictionlessdata.io/tabular-data-resource/	null	no	csv-specific	`null`
258	OKF Tabular Data Package	https://specs.frictionlessdata.io/tabular-data-package/	null	no	csv-specific	`null`
259	IETF GeoJSON	https://geojson.org/	null	no	geojson-specific	`null`
260	OGC GeoPackage	https://en.wikipedia.org/wiki/GeoPackage	null	no	geopackage-specific	`null`
261	GDAL Documentation sec Vector drivers	https://gdal.org/drivers/vector/csv.html	null	no	not standards	GDAL-accepted geospatial data formats
262	Nature Scientific Data Policies sec Data Repository Guidance	https://www.nature.com/sdata/policies/repositories	null	no	not standards	Nature-listed repositories
263	Google Search Central Documentation sec Dataset	https://developers.google.com/search/docs/advanced/structured-data/dataset	null	no	not standards	Google-indexed repositories
264	The Linked Open Data Cloud	https://lod-cloud.net/	null	no	not standards	LOD Cloud-indexed repositories
265	Wolfram MathWorld Pseudograph	https://mathworld.wolfram.com/Pseudograph.html	null	no	not standards	`null`
266	nLab pseudograph	https://ncatlab.org/nlab/show/pseudograph	null	no	not standards	`null`
267	TEI	https://tei-c.org/release/doc/tei-p5-doc/en/html/index.html	null	no	not standards or xml-specific	`null`
268	RDF	http://www.w3.org/TR/rdf-primer	null	no	not standards or rdf-specific	`null`
269	RDF Schema ie RDFS	https://en.wikipedia.org/wiki/RDF_Schema	null	no	not standards or rdf-specific	`null`
270	RDF Data Cube	https://www.w3.org/TR/vocab-data-cube/	null	no	not standards or rdf-specific	`null`
271	XML	https://en.wikipedia.org/wiki/XML	null	no	not standards or xml-specific	`null`
272	XML Schema	https://en.wikipedia.org/wiki/XML_Schema_(W3C)	null	no	not standards or xml-specific	`null`
273	JSON	https://en.wikipedia.org/wiki/JSON	null	no	not standards or json-specific	`null`
274	RDF Data Cube Extensions	https://www.w3.org/TR/qb4st/	null	no	not standards or rdf-specific	`null`
275	JSON-LD	https://en.wikipedia.org/wiki/JSON-LD	null	no	not standards or json-ld-specific	`null`
276	CSV by W3C	https://www.w3.org/2013/csvw/wiki/Main_Page	null	no	not standards or csv-specific	`null`
277	CSV by FD	https://specs.frictionlessdata.io//tabular-data-package/	null	no	not standards or csv-specific	`null`
278	CSV by JT	https://github.com/JeniT/linked-csv	null	no	not standards or csv-specific	`null`
279	OWL	http://www.w3.org/TR/owl-overview	null	no	not standards or owl-specific	`null`
280	QNames for XML	http://www.w3.org/TR/xml-names11	null	no	not standards or xml-specific	xml-specific namespaces ie vocabs
281	CURIEs	http://www.w3.org/TR/curie	null	no	not standards	language-independent namespaces ie vocabs
282	BFO	http://xmlns.com/foaf/spec/	null	no	not standards	upper-level ontology
283	schema.org	https://schema.org/	null	no	not standards	upper-level ontology
284	WikiData	https://www.wikidata.org/wiki/Wikidata:Main_Page	null	no	not standards	upper-level ontology
285	DBpedia	https://www.dbpedia.org/about/	null	no	not standards	"upper-level ontology, derivative of WikiData"
286	gist	https://www.semanticarts.com/gist/	null	no	not standards	upper-level ontology
287	LOV Directory	https://lov.linkeddata.es/dataset/lov/	null	no	not standards	directory for commonest vocabs or upper-level ontologies
288	LCNAF	http://id.loc.gov/authorities/names.html	null	no	not standards	vocab for authorities ie authors etc
289	VIAF	https://viaf.org/	null	no	not standards	vocab for authorities ie authors etc
290	ISNI	https://isni.oclc.org/xslt/	null	no	not standards	vocab for authorities ie authors etc
291	ORG	http://www.w3.org/TR/vocab-org/	null	no	not standards	vocab for non-natural persons
292	FOAF	http://xmlns.com/foaf/spec/	null	no	not standards	vocab for human networks ie human-human relations ie edges
293	ISO 639	https://www.loc.gov/standards/iso639-2/php/code_list.php	null	no	not standards	vocab for language data values
294	ISO 8601	https://www.iso.org/iso-8601-date-and-time-format.html	null	no	not standards	vocab for date-time values
295	ISO 4217	https://www.iso.org/iso-4217-currency-codes.html	null	no	not standards	vocab for currency values
296	ISO 3166	https://www.iso.org/iso-3166-country-codes.html	null	no	not standards	vocab for country values
297	Getty TGN	http://www.getty.edu/research/tools/vocabularies/tgn/index.html	null	no	not standards	vocab for geographic data
298	GeoNames	https://www.geonames.org/	null	no	not standards	vocab for geographic data
299	LinkedGeoData	http://linkedgeodata.org/	null	no	not standards	vocab for geographic data
300	LCSH	http://id.loc.gov/authorities/subjects.html	null	no	not standards	vocab for bibliography ie cataloguing
301	FAST	https://www.oclc.org/research/areas/data-science/fast.html	null	no	not standards	"vocab for bibliography ie cataloguing, is derivative of LCSH"
302	UNESCO	http://vocabularies.unesco.org/thesaurus	null	no	not standards	vocab for bibliography ie cataloguing
303	ICPSR	https://www.icpsr.umich.edu/icpsrweb/ICPSR/thesaurus/index	null	no	not standards	vocab for bibliography ie cataloguing
304	CIDOC CRM	https://cidoc-crm.org/	null	no	not standards	vocab for bibliography ie cataloguing
305	EAD	https://en.wikipedia.org/wiki/Encoded_Archival_Description	null	no	not standards	vocab for bibliography ie cataloguing
306	Dublin Core ie DCMI	https://www.dublincore.org/	null	no	not standards	vocab for metadata
307	IOA	https://ontobee.org/ontology/IAO	null	no	not standards	vocab for metadata
308	DDI	http://www.ddialliance.org/controlled-vocabularies	null	no	not standards	vocab for metadata
309	SKOS	http://www.w3.org/2004/02/skos/core	null	no	not standards	vocab for metadata
310	DCAT	https://www.w3.org/TR/vocab-dcat/	null	no	not standards	vocab for metadata
311	VOID	http://www.w3.org/TR/void/	null	no	not standards	"vocab for metadata, is a derivative of Dublin Core and RDF Schema"
312	QUDT	https://www.qudt.org/	null	no	not standards	vocab for metadata esp datatypes
313	CC	https://lov.linkeddata.es/dataset/lov/vocabs/cc	null	no	not standards	vocab for licensing
314	PURL	https://purl.archive.org/	null	no	not standards	http URI service
315	PermID	http://permid.org/	null	no	not standards	http URI service
316	W3ID	https://rml.io/yarrrml/matey	null	no	not standards	http URI service